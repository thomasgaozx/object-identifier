{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport torchvision.transforms.functional as TF\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\ncudnn.benchmark = True\nplt.ion()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(device)\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Batch size during training\nbatch_size = 55\n\n# Spatial size of training images. All images will be resized to this\n#   size using a transformer.\nimage_size = 64\n\n# Number of channels in the training images. For color images this is 3\nnc = 3\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input/cs480winter2022/5_shot/5_shot/test'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T03:26:10.871062Z","iopub.execute_input":"2022-04-12T03:26:10.873720Z","iopub.status.idle":"2022-04-12T03:26:12.356640Z","shell.execute_reply.started":"2022-04-12T03:26:10.873379Z","shell.execute_reply":"2022-04-12T03:26:12.355240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model,\n               dataloader,\n               criterion,\n               optimizer,\n               scheduler,\n               num_epochs=50,\n               plot=True):\n    dataset_size = len(dataloader.dataset)\n    since = time.time()\n    \n    #best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    train_acc = np.zeros(num_epochs)\n    train_loss = np.zeros(num_epochs)\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n        \n        for inputs, labels in dataloader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            # zero the parameter gradients\n            optimizer.zero_grad()\n            \n            with torch.set_grad_enabled(True):\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n                \n                loss.backward()\n                optimizer.step()\n            \n            # statistics\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n            \n            scheduler.step()\n        \n            epoch_loss = running_loss / dataset_size\n            epoch_acc = running_corrects.double() / dataset_size\n            \n            train_loss[epoch] = epoch_loss\n            train_acc[epoch] = epoch_acc\n\n        if epoch % 10 == 0:\n            torch.save(model, f\"/kaggle/working/testmodel_epoch{epoch}\")\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # plotting\n    if plot:\n        epoches = list(range(num_epochs))\n        \n        plt.figure()\n        plt.plot(epoches, train_acc, label=\"train accuracy\")\n        #plt.plot(epoches, test_acc, label=\"test accuracy\")\n        #plt.legend()\n        plt.xlabel(\"epoch\")\n        plt.ylabel(\"accuracy\")\n        plt.title(\"Accuracy vs Epoch\")\n        \n        plt.figure()\n        plt.plot(epoches, train_loss, label=\"train loss\")\n        #plt.plot(epoches, test_loss, label=\"test loss\")\n        #plt.legend()\n        plt.xlabel(\"epoch\")\n        plt.ylabel(\"loss\")\n        plt.title(\"Loss vs Epoch\")\n\n    # load best model weights\n    #model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:26:12.358471Z","iopub.execute_input":"2022-04-12T03:26:12.358895Z","iopub.status.idle":"2022-04-12T03:26:12.372448Z","shell.execute_reply.started":"2022-04-12T03:26:12.358856Z","shell.execute_reply":"2022-04-12T03:26:12.371701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resize = transforms.Compose([\n    #transforms.Grayscale(num_output_channels=1),\n    #transforms.RandomResizedCrop(image_size, interpolation=transforms.InterpolationMode.BICUBIC),\n    transforms.RandomResizedCrop(image_size, \n                             scale=(0.8, 1.0),\n                             ratio=(0.9,1.1),\n                             interpolation=transforms.InterpolationMode.BICUBIC),\n\n    #transforms.Resize((image_size, 90), interpolation=transforms.InterpolationMode.BICUBIC),\n    #transforms.CenterCrop(image_size),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomAdjustSharpness(1.25, p=0.8),\n    #transforms.RandomVerticalFlip(),\n    transforms.ColorJitter( brightness=0.15, contrast=0.15, saturation=0.15, ),\n    #transforms.RandomRotation(90),\n    transforms.ToTensor(),\n    #,\n    #transforms.RandomAutocontrast(p=0.5),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ])\ntraining_data = datasets.ImageFolder(\"/kaggle/input/cs480winter2022/5_shot/5_shot/train\",\n                                     transform=resize)\n#testing_data = datasets.ImageFolder(\"/kaggle/input/cs480winter2022/5_shot/5_shot/test\")\nprint(training_data)\n#print(testing_data)\ntrain_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n\n# =============> sampling images\nfor i, data in enumerate(train_loader):\n    print(data[0].shape, data[1].shape)\n    tensor_image = data[0][0]\n    plt.figure()\n    plt.imshow(  tensor_image.permute(1, 2, 0)  )\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:26:12.373614Z","iopub.execute_input":"2022-04-12T03:26:12.373855Z","iopub.status.idle":"2022-04-12T03:26:15.023771Z","shell.execute_reply.started":"2022-04-12T03:26:12.373822Z","shell.execute_reply":"2022-04-12T03:26:15.022464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(training_data.classes)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:26:15.025627Z","iopub.execute_input":"2022-04-12T03:26:15.025959Z","iopub.status.idle":"2022-04-12T03:26:15.030401Z","shell.execute_reply.started":"2022-04-12T03:26:15.025922Z","shell.execute_reply":"2022-04-12T03:26:15.029702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# attempt #1 baseline:\n# model = models.resnet50().to(device)\n# criterion = nn.CrossEntropyLoss()\n# # Observe that all parameters are being optimized\n# #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.7)\n# lr = 0.001\n# beta1 = 0.5\n# optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, 0.999))\n# # Decay LR by a factor of 0.1 every 7 epochs\n# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n\n\n# Experiment Tutorial:\n# https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n# ConvNet as fixed feature extractor\n# model = models.resnet50(pretrained=True)\n# for param in model.parameters():\n#     param.requires_grad = False\n\n# num_cls = len(training_data.classes) # 22 image classes\n# num_ftrs = model.fc.in_features\n# model.fc = nn.Linear(num_ftrs, num_cls)\n# model = model.to(device)\n\n# criterion = nn.CrossEntropyLoss()\n# lr = 0.0015\n# beta1 = 0.5\n# optimizer = optim.Adam(model.fc.parameters(), lr=lr,\n#                        betas=(beta1, 0.999))\n\n# Finetuning the convnet\nmodel = models.resnet50(pretrained=True)\n\nnum_cls = len(training_data.classes) # 22 image classes\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, num_cls)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\nlr = 0.000125 # slower LR cuz already pre-trained\nbeta1 = 0.5\noptimizer = optim.Adam(model.parameters(), lr=lr,\n                       betas=(beta1, 0.999))\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\nmodel = train_model(model,\n                    train_loader,\n                    criterion,\n                    optimizer,\n                    exp_lr_scheduler,\n                    num_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:26:15.031979Z","iopub.execute_input":"2022-04-12T03:26:15.032753Z","iopub.status.idle":"2022-04-12T03:26:47.961519Z","shell.execute_reply.started":"2022-04-12T03:26:15.032700Z","shell.execute_reply":"2022-04-12T03:26:47.960059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def produce_output(model, dataloader):\n#     dataset_size = len(dataloader.dataset)\n#     model.eval()\n\n#     for inputs, labels in dataloader:\n#         inputs = inputs.to(device)\n\n#         outputs = model(inputs)\n#         _, preds = torch.max(outputs, 1)\nfrom PIL import Image\n\ntest_size = 517\nimgs = torch.stack(\n    [TF.to_tensor(\n        Image.open(f\"/kaggle/input/cs480winter2022/5_shot/5_shot/test/{i}.jpg\")\n    ) for i in range(test_size) ])\n\nprocess = transforms.Compose([\n    transforms.Resize((image_size+10, 110), interpolation=transforms.InterpolationMode.BICUBIC),\n    #transforms.Resize((image_size, 100), interpolation=transforms.InterpolationMode.BICUBIC),\n    transforms.CenterCrop(image_size),\n    transforms.RandomAdjustSharpness(1.15, p=1),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    ])\nimgs = process(imgs)\nprint(imgs.shape)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:26:47.962864Z","iopub.execute_input":"2022-04-12T03:26:47.963211Z","iopub.status.idle":"2022-04-12T03:27:02.690494Z","shell.execute_reply.started":"2022-04-12T03:26:47.963158Z","shell.execute_reply":"2022-04-12T03:27:02.689045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimgs = imgs.to(device)\noutputs = model(imgs)\n_, preds = torch.max(outputs, 1)\npreds = preds.cpu()\ndf = pd.DataFrame({\n    \"id\": list(range(test_size)),\n    \"category\": [int(training_data.classes[i]) for i in preds]\n})\n#print(preds)\n#print(df.head(10))\n\nprint(df.to_csv(index=False))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T03:27:02.691930Z","iopub.execute_input":"2022-04-12T03:27:02.692261Z","iopub.status.idle":"2022-04-12T03:27:03.803537Z","shell.execute_reply.started":"2022-04-12T03:27:02.692221Z","shell.execute_reply":"2022-04-12T03:27:03.802777Z"},"trusted":true},"execution_count":null,"outputs":[]}]}